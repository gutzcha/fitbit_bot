================================================================================
FITBIT CONVERSATIONAL AI POC - ASSIGNMENT PLAN
================================================================================

Based on: Senior_Data_Scientist_Home_Assignment.pdf
Hello Heart - Healthy Hearts, Healthy People

================================================================================
1. TECHNICAL DESIGN DOCUMENT (1-2 pages)
================================================================================

1.1 LOGICAL ARCHITECTURE & INFORMATION FLOW
-------------------------------------------
- Diagram/Description Components:
  * User Input â†’ Intent Classification
  * Intent â†’ Context Retrieval (SQL queries + RAG knowledge base)
  * Context â†’ Response Synthesis (with personalization)
  * Response â†’ Follow-up Suggestions Generation

- Flow Diagram:
  User Query
    â†“
  Intent Detection Node (LangGraph)
    â”œâ”€â†’ Low Confidence â†’ Clarification Node
    â”œâ”€â†’ Static Intent (GREETING, OUT_OF_SCOPE) â†’ Static Response Node
    â””â”€â†’ Data Query Intent â†’ Process Subgraph
         â†“
      Process Subgraph:
         â”œâ”€â†’ Planner Node (creates execution plan)
         â”œâ”€â†’ Execution Agent Node (SQL queries + RAG retrieval)
         â””â”€â†’ Suggestor Node (adds coaching suggestions)
         â†“
      Final Response (personalized, data-driven)

1.2 LLM ORCHESTRATION FRAMEWORK
-------------------------------
- Framework: LangGraph (state-based graph orchestration)
- Why LangGraph:
  * Explicit control flow with conditional routing
  * State management across conversation turns
  * Easy to add/remove nodes and edges
  * Built-in checkpointing for conversation memory
  * Supports multi-agent workflows (Planner, Executor, Suggestor)

- Architecture Layers:
  * Top-level Graph: Intent â†’ Clarification/Static/Process routing
  * Process Subgraph: Planner â†’ Executor â†’ Suggestor pipeline
  * RAG Subgraph: Retrieve â†’ Grade â†’ Generate for knowledge base

1.3 DATA REPRESENTATION & CONTEXT STRATEGY
-------------------------------------------
- Mock Health Data Structure:
  * SQLite Database: Daily activity, heart rate, steps, calories, weight
  * User Profiles (JSON): Goals, body metrics, coaching preferences
  * Schema: Normalized tables with date-based queries

- Context Strategy:
  * Conversation History: LangGraph MemorySaver (thread-based)
  * User Profile: Injected into state at conversation start
  * Data Context: Retrieved via SQL tools (structured queries)
  * Knowledge Context: Retrieved via RAG (semantic search)
  * Context Window Management: Configurable max_history_limit (default: 10 turns)

- Data Format for LLM:
  * SQL Results: Formatted as structured text with clear labels
  * User Profile: JSON summary (goals, body, preferences)
  * Knowledge Base: Retrieved chunks with metadata (source, relevance)

1.4 PROMPT STRATEGY AND AGENT BEHAVIOR
--------------------------------------
- Intent Detection:
  * Fast LLM (mistral:8b) for initial classification
  * Slow fallback (if confidence < 0.9) for uncertain cases
  * Structured output: Intent enum + confidence score + needs_clarification flag

- Planner Agent:
  * Chain-of-Thought reasoning: "Let me break down what data I need..."
  * Output: Structured plan with steps, required tools, expected outputs
  * Handles missing data gracefully (sets needs_clarification flag)

- Execution Agent:
  * Tool-calling approach: SQL tools + RAG retriever
  * Pre-defined tools for common queries (steps, heart rate, calories)
  * Fallback tool for custom SQL generation
  * Grounding: Only uses retrieved data, no hallucinations

- Suggestor Agent:
  * Input: User profile + retrieved data + conversation context
  * Output: Personalized coaching suggestions
  * Tone: Encouraging, empathetic, non-medical
  * Format: Natural language with specific data references

- Prompt Engineering Techniques:
  * Few-shot examples for intent classification
  * System prompts with persona definition ("encouraging health coach")
  * Chain-of-Thought for complex reasoning
  * Structured output schemas (Pydantic models)

1.5 EVALUATION FRAMEWORK
-------------------------
- Metrics for Success:
  * Factual Accuracy: % of responses correctly grounded in data
  * Tone Consistency: LLM-as-judge evaluation of empathy/encouragement
  * Relevance: % of responses that directly address user query
  * Personalization: % of responses that reference specific user data
  * Context Retention: Ability to reference earlier conversation turns

- Automated Evaluation Pipeline:
  * Test Suite: Pre-defined conversation flows with expected behaviors
  * LLM-as-Judge: Use Claude/Anthropic to evaluate response quality
  * Grounding Check: Verify all data claims can be traced to source
  * A/B Testing: Compare different prompt strategies
  * User Feedback Simulation: Thumbs up/down â†’ retraining signal

- Evaluation Dataset:
  * Sample queries covering all intent types
  * Edge cases: Missing data, ambiguous queries, out-of-scope
  * Multi-turn conversations to test context retention

================================================================================
2. WORKING CODE (GitHub repo)
================================================================================

2.1 PROJECT STRUCTURE
---------------------
âœ“ Implemented:
  * graph/ - LangGraph orchestration
  * graph/nodes/ - Intent, Clarification, Static Response nodes
  * graph/process/ - Process subgraph (Planner, Executor, Suggestor)
  * graph/tools/ - SQL tools and RAG retriever
  * app/ - Streamlit UI
  * dataset/ - Mock Fitbit data (SQLite + user profiles)
  * tests/ - Unit and integration tests

2.2 KEY FEATURES IMPLEMENTED
-----------------------------
âœ“ User Query Understanding:
  * Intent classification with confidence scoring
  * Clarification requests for ambiguous queries
  * Handles: data queries, greetings, out-of-scope

âœ“ Health Insight Generation:
  * SQL queries for steps, heart rate, calories, sleep, weight
  * RAG retrieval for health knowledge base
  * Personalized insights based on user profile

âœ“ Follow-up & Suggestions:
  * Suggestor node adds coaching suggestions
  * References user goals and preferences
  * Context-aware (remembers conversation history)

âœ“ Quality Requirements:
  * Grounding: All responses traceable to data sources
  * Tone: Encouraging, empathetic prompts
  * Context Retention: LangGraph MemorySaver
  * Personalization: Explicit data references in responses

2.3 DEMONSTRATION CONVERSATIONS
--------------------------------
Example 1: Personalized Insight
  User: "How are my steps looking today?"
  System: "You've taken 8,234 steps today, which is 82% of your daily goal of 10,000. 
           You're on track! Based on your weekly average, you typically reach your 
           goal by 6 PM. Keep it up!"

Example 2: Follow-up Question
  User: "What about my heart rate?"
  System: "Your resting heart rate today is 62 bpm, which is excellent and consistent 
           with your recent trend. Your active heart rate during your morning walk 
           peaked at 145 bpm, putting you in the fat burn zone. 
           [Suggestion] Would you like a reminder to do a 10-minute breathing exercise 
           tonight to help lower your resting heart rate further?"

Example 3: Simple Query Handling
  User: "Am I more active this week than last week?"
  System: "Yes! This week you've averaged 9,200 steps per day compared to 7,800 last 
           week - that's an 18% increase. Your most active day was Tuesday with 
           12,450 steps. Great progress toward your weekly goal!"

2.4 NOTEBOOK DEMONSTRATION
---------------------------
âœ“ notebooks/ directory includes:
  * debug_graph.ipynb - Graph execution visualization
  * execution_agent_sandbox.ipynb - Tool testing
  * sql_sandbox.ipynb - SQL query examples
  * kb_sandbox.ipynb - RAG retrieval testing
  * graphs_sandbox.ipynb - Graph architecture exploration

================================================================================
3. PRODUCTIZATION PLAN
================================================================================

3.1 PRODUCTION READINESS STEPS
-------------------------------
Phase 1: Infrastructure (Weeks 1-2)
  * Move from SQLite to production database (PostgreSQL/MySQL)
  * Deploy vector database (Pinecone/Weaviate for scale)
  * Set up API gateway (FastAPI + authentication)
  * Implement rate limiting and request validation
  * Add monitoring (Prometheus, Grafana)

Phase 2: Scalability (Weeks 3-4)
  * Horizontal scaling: Multiple graph execution workers
  * Caching layer: Redis for frequently accessed data
  * Async processing: Background jobs for heavy queries
  * Load balancing: Distribute requests across instances
  * Database connection pooling

Phase 3: Reliability (Weeks 5-6)
  * Error handling: Graceful degradation on failures
  * Retry logic: Exponential backoff for external APIs
  * Circuit breakers: Prevent cascade failures
  * Health checks: Automated monitoring and alerts
  * Backup and disaster recovery

Phase 4: Security & Compliance (Weeks 7-8)
  * HIPAA compliance: Encrypted data at rest and in transit
  * Authentication: OAuth 2.0 / JWT tokens
  * Authorization: Role-based access control
  * Audit logging: Track all data access
  * Data anonymization: PII removal for analytics

3.2 FEEDBACK LOOPS & MODEL IMPROVEMENT
---------------------------------------
Feedback Collection:
  * In-app: Thumbs up/down on each response
  * Explicit: "Was this helpful?" prompts
  * Implicit: User engagement metrics (response time, follow-up questions)
  * A/B Testing: Compare prompt variations

Feedback Processing:
  * Store feedback in database with:
    - User ID, timestamp, query, response, rating
    - Conversation context (previous turns)
    - Data sources used
  * Aggregate feedback by:
    - Intent type
    - Response quality score
    - User segment (new vs. returning)

Model Improvement Strategy:
  * Identify "bad" responses:
    - Low ratings (< 3/5 stars)
    - High clarification request rate
    - User corrections ("That's not right")
  * Root Cause Analysis:
    - Hallucination detection: Compare claims to data sources
    - Tone issues: Sentiment analysis on feedback
    - Missing context: Identify gaps in knowledge base
  * Fixes:
    - Prompt engineering: Refine system prompts based on failures
    - Fine-tuning: Retrain on high-quality conversation examples
    - Knowledge base expansion: Add missing information
    - Tool improvements: Better SQL generation, RAG retrieval

Continuous Learning:
  * Weekly review of feedback trends
  * Monthly model updates with new training data
  * Quarterly evaluation against test suite
  * Annual comprehensive review and architecture updates

3.3 OPPORTUNITIES FOR IMPROVEMENT AND RESEARCH
----------------------------------------------
Short-term (3-6 months):
  * Multi-modal Input: Voice queries, image analysis (food photos)
  * Proactive Nudges: Push notifications based on patterns
  * Goal Tracking: Visual progress indicators
  * Social Features: Share achievements, challenges with friends

Medium-term (6-12 months):
  * Clinical Validation: Partner with healthcare providers
  * Predictive Analytics: Forecast health trends
  * Personalized Workout Plans: AI-generated exercise routines
  * Nutrition Recommendations: Meal planning based on activity

Long-term (12+ months):
  * Wearable Integration: Real-time data from multiple devices
  * Telemedicine Integration: Connect with healthcare providers
  * Research Participation: Opt-in for health studies
  * Advanced Personalization: User-specific model fine-tuning

Research Directions:
  * Few-shot Learning: Reduce need for large training datasets
  * Retrieval-Augmented Generation: Improve RAG accuracy
  * Multi-agent Collaboration: Better coordination between agents
  * Explainable AI: Show reasoning process to users
  * Privacy-Preserving ML: Federated learning for personalization

3.4 RISK MITIGATION
-------------------
Technical Risks:
  * LLM Hallucinations â†’ Implement strict grounding checks
  * Data Quality Issues â†’ Validation pipelines, data quality metrics
  * Scalability Bottlenecks â†’ Load testing, performance monitoring
  * API Rate Limits â†’ Caching, request batching, fallback providers

Business Risks:
  * User Trust â†’ Transparency in data usage, clear privacy policy
  * Regulatory Compliance â†’ Legal review, compliance audits
  * Cost Management â†’ Monitor API usage, optimize prompts
  * Competition â†’ Focus on unique value (personalization, data integration)

================================================================================
4. IMPLEMENTATION STATUS
================================================================================

âœ“ COMPLETED:
  - LangGraph architecture with multi-stage routing
  - Intent classification with confidence scoring
  - SQL query tools for health data
  - RAG knowledge base retrieval
  - Planner-Executor-Suggestor pipeline
  - Streamlit UI for interaction
  - User profile integration
  - Conversation memory management
  - Multi-provider LLM support (Ollama, Anthropic)

ðŸ”„ IN PROGRESS / TO IMPROVE:
  - Evaluation framework (test suite exists, needs expansion)
  - Production deployment infrastructure
  - Feedback collection system
  - Advanced personalization features

ðŸ“‹ TODO:
  - Comprehensive test coverage
  - Performance optimization
  - Security hardening
  - Documentation expansion

================================================================================
5. DELIVERABLES CHECKLIST
================================================================================

âœ“ Technical Design Document (this plan + code comments)
âœ“ Working Code (GitHub repo with full implementation)
âœ“ Notebook Demonstrations (notebooks/ directory)
âœ“ Productization Plan (Section 3 above)
âœ“ Evaluation Framework (Section 1.5 + tests/)

================================================================================
END OF PLAN
================================================================================
